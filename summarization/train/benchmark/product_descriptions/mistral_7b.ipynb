{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import torch \n",
    "import pandas as pd\n",
    "from torchmetrics.text import ROUGEScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = ROUGEScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0.0, top_p=0.95, max_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"Give a concise summary for the below description of the product.\\n\\nProduct Description:\\n{description}\\n\\nSummary:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = pd.read_csv(\"../../../data/labelled/metadata/splits/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_info</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;b&gt;CONTENTS  - In the Friendly Swede Retail pa...</td>\n",
       "      <td>The Friendly Swede Retail packaging includes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMPIRE's two piece snap-on cases are made of h...</td>\n",
       "      <td>EMPIRE's two piece snap-on cases provide maxim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_info  \\\n",
       "0  <b>CONTENTS  - In the Friendly Swede Retail pa...   \n",
       "1  EMPIRE's two piece snap-on cases are made of h...   \n",
       "\n",
       "                                             summary  \n",
       "0  The Friendly Swede Retail packaging includes a...  \n",
       "1  EMPIRE's two piece snap-on cases provide maxim...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desc_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-14 04:27:13 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-14 04:27:13 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='mistralai/Mistral-7B-Instruct-v0.1', tokenizer='mistralai/Mistral-7B-Instruct-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-14 04:27:13 selector.py:45] Cannot use FlashAttention because the package is not found. Please install it for better performance.\n",
      "INFO 04-14 04:27:13 selector.py:21] Using XFormers backend.\n",
      "INFO 04-14 04:27:15 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "INFO 04-14 04:27:21 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 04-14 04:27:23 gpu_executor.py:94] # GPU blocks: 29400, # CPU blocks: 2048\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"mistralai/Mistral-7B-Instruct-v0.1\", dtype=torch.float16, gpu_memory_utilization=0.95, enforce_eager=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for idx in range(0, len(desc_df), batch_size):\n",
    "    batch = desc_df[idx:idx+batch_size]\n",
    "    descs = batch.product_info.to_list()\n",
    "    labels = batch.summary.to_list()\n",
    "    input_batch = [\"<s>[INST] \"+instruction.format_map({\"description\":desc})+\" [/INST]\" for desc in descs]\n",
    "    outputs = llm.generate(input_batch, sampling_params, use_tqdm=False)\n",
    "    preds.extend([out.outputs[0].text.strip() for out in outputs])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df['mistral'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"mistral_results_descs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = {\"rouge1\":[], \"rouge2\":[], \"rougeL\": []}\n",
    "for pred, target in zip(desc_df.summary.to_list(), desc_df.mistral.to_list()):\n",
    "    rouge_all = rouge(pred, target)\n",
    "    rouge_scores['rouge1'].append(rouge_all['rouge1_fmeasure'].item())\n",
    "    rouge_scores['rouge2'].append(rouge_all['rouge2_fmeasure'].item())\n",
    "    rouge_scores['rougeL'].append(rouge_all['rougeL_fmeasure'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df['rouge1'] = rouge_scores['rouge1']\n",
    "desc_df['rouge2'] = rouge_scores['rouge2']\n",
    "desc_df['rougeL'] = rouge_scores['rougeL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"mistral_results_descs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"rouge1\": desc_df.rouge1.mean(), \"rouge2\": desc_df.rouge2.mean(), \"rougeL\": desc_df.rougeL.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6448089795753349,\n",
       " 'rouge2': 0.4536853957320061,\n",
       " 'rougeL': 0.5512770770484734}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
